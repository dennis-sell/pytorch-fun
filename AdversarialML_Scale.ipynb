{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdversarialML@Scale.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dennis-sell/pytorch-fun/blob/master/AdversarialML_Scale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Gm2FWxu9wpbK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Adversarial Machine Learning at Scale\n",
        "Based on the paper by Kurakin, Goodfellow, and Bengio and published as a conference paper at ICLR 2017.\n",
        "It explores several attacks on blackbox Classification neural nets, as well as defense methods which involve training against these attacks during model creation - hence the phrase adversarial training. \n",
        "\n",
        "Key concepts include transferability of attacks across models, the topic of label leaking, and the comparison of susceptibility to adversarial attacks with overfitting. Given this last point they compare their defense methods to regularization, which seems apt given the relationship between adversarial training, model accuracy, and model capacity. \n",
        "\n",
        "Additionally, the results of the paper indicate that a blackbox machine learning model can protect itself from any reasonable attack by using adversarial training. However, this does not come for free and may slightly hurt the model's performance on the intended dataset."
      ]
    },
    {
      "metadata": {
        "id": "sbNOo2OWL5Hd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as tv_datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ttzSfEewTMkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "247859d3-19d7-4c0b-dfc8-2e64165dae27"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_dir = 'drive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cbt132MdzFze",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MDjA9bgsL-3p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_step_least_likely_attack(image, epsilon, data_grad):\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    perturbed_image = image - epsilon*sign_data_grad\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tXHamW13OKsN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Choosing Models\n",
        "The paper claims that single-iteration attacks are quite transferable across models, regardless of weights or even architectures. Neverthless let's start off simple with two relatively similar models. The more advanced model has a few more layers and is trained using Batch Normalization, but it is still fundamenetally the same model. \n",
        "\n",
        "This should be a good starting place for us. We can build attacks from the simpler VGG model and then attack the more complicated one. "
      ]
    },
    {
      "metadata": {
        "id": "3zXdm5KNMq2a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#vgg16_bn = models.vgg16_bn(pretrained=True)\n",
        "#vgg13 = models.vgg16(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W30rq6vrjWvN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It can be difficult to get the imagenet dataset, but I decided to put in the work to get it. The paper was written w/ ImageNet in mind, and that is a much more interesting data set (256x256x3) than say MNIST (28x28x1) or CIFAR (32x32x3).\n",
        "\n",
        "You can use this: https://github.com/tzutalin/ImageNet_Utils\n",
        "The imagenet site will only directly give you the images if you are a researcher, but you can always get the URLS of where they are hosted and then download them one by one."
      ]
    },
    {
      "metadata": {
        "id": "PC5yl39rwnuW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Backup Plan: CIFAR\n",
        "\n",
        "Can also use CIFAR dataset since that is easier. Follow the [tutorial for an example](https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/cifar10_tutorial.py)\n",
        "\n",
        "Not a huge fan of the fact that there is no matching model-dataset pair for vision problems in pytorch."
      ]
    },
    {
      "metadata": {
        "id": "qx81azmmzOZe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copy model def from other class\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mBZ3U5ty1IE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a42c75dd-8e63-4b98-8302-2093752dc7d9"
      },
      "cell_type": "code",
      "source": [
        "# Get pre-trained model (See cifar script for how it is generated)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "cifar10_cnn = Net()\n",
        "\n",
        "cifar10_cnn.load_state_dict(torch.load(drive_dir + 'data/cifar10.pt'))\n",
        "\n",
        "# Get data from pytorch\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "dataiter = iter(testloader)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VXHCe5CxtuPS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4676603b-d621-4f18-97f3-52f46f0d13d8"
      },
      "cell_type": "code",
      "source": [
        "# Test that the model is ok.\n",
        "images, labels = dataiter.next()\n",
        "raw_outputs = cifar10_cnn(images)\n",
        "_, predicted = torch.max(raw_outputs.data, 1)\n",
        "num_correct = (predicted == labels).sum().item()\n",
        "total = labels.size(0)\n",
        "print('Accuracy: %d / %d' % (num_correct, total))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 7 / 10\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}